# Generated from conversionLexer.g4 by ANTLR 4.11.1
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,7,141,6,-1,6,-1,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,
        2,5,7,5,2,6,7,6,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,
        1,0,1,0,1,0,1,0,5,0,34,8,0,10,0,12,0,37,9,0,3,0,39,8,0,1,0,3,0,42,
        8,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
        1,1,1,1,1,1,1,1,1,1,3,1,64,8,1,1,1,1,1,1,1,1,1,1,2,5,2,71,8,2,10,
        2,12,2,74,9,2,1,2,3,2,77,8,2,1,2,1,2,1,2,1,2,1,3,1,3,1,3,1,3,1,3,
        1,3,1,3,1,3,1,3,1,3,1,3,3,3,94,8,3,1,3,1,3,1,3,1,3,1,4,5,4,101,8,
        4,10,4,12,4,104,9,4,1,4,3,4,107,8,4,1,4,1,4,1,5,1,5,1,5,1,5,1,5,
        1,5,1,5,1,5,1,5,1,5,1,5,1,5,1,5,1,5,3,5,125,8,5,1,5,1,5,1,5,1,5,
        1,6,5,6,132,8,6,10,6,12,6,135,9,6,1,6,3,6,138,8,6,1,6,1,6,3,72,102,
        133,0,7,3,1,5,2,7,3,9,4,11,5,13,6,15,7,3,0,1,2,1,4,0,48,57,65,90,
        95,95,97,122,150,0,3,1,0,0,0,0,5,1,0,0,0,0,7,1,0,0,0,1,9,1,0,0,0,
        1,11,1,0,0,0,2,13,1,0,0,0,2,15,1,0,0,0,3,17,1,0,0,0,5,47,1,0,0,0,
        7,72,1,0,0,0,9,82,1,0,0,0,11,102,1,0,0,0,13,110,1,0,0,0,15,133,1,
        0,0,0,17,18,5,64,0,0,18,19,5,98,0,0,19,20,5,101,0,0,20,21,5,103,
        0,0,21,22,5,105,0,0,22,23,5,110,0,0,23,24,5,61,0,0,24,25,5,118,0,
        0,25,26,5,102,0,0,26,27,5,112,0,0,27,28,5,64,0,0,28,38,1,0,0,0,29,
        30,5,38,0,0,30,31,5,38,0,0,31,35,1,0,0,0,32,34,7,0,0,0,33,32,1,0,
        0,0,34,37,1,0,0,0,35,33,1,0,0,0,35,36,1,0,0,0,36,39,1,0,0,0,37,35,
        1,0,0,0,38,29,1,0,0,0,38,39,1,0,0,0,39,41,1,0,0,0,40,42,5,13,0,0,
        41,40,1,0,0,0,41,42,1,0,0,0,42,43,1,0,0,0,43,44,5,10,0,0,44,45,1,
        0,0,0,45,46,6,0,0,0,46,4,1,0,0,0,47,48,5,64,0,0,48,49,5,98,0,0,49,
        50,5,101,0,0,50,51,5,103,0,0,51,52,5,105,0,0,52,53,5,110,0,0,53,
        54,5,61,0,0,54,55,5,112,0,0,55,56,5,121,0,0,56,57,5,116,0,0,57,58,
        5,104,0,0,58,59,5,111,0,0,59,60,5,110,0,0,60,61,5,64,0,0,61,63,1,
        0,0,0,62,64,5,13,0,0,63,62,1,0,0,0,63,64,1,0,0,0,64,65,1,0,0,0,65,
        66,5,10,0,0,66,67,1,0,0,0,67,68,6,1,1,0,68,6,1,0,0,0,69,71,9,0,0,
        0,70,69,1,0,0,0,71,74,1,0,0,0,72,73,1,0,0,0,72,70,1,0,0,0,73,76,
        1,0,0,0,74,72,1,0,0,0,75,77,5,13,0,0,76,75,1,0,0,0,76,77,1,0,0,0,
        77,78,1,0,0,0,78,79,5,10,0,0,79,80,1,0,0,0,80,81,6,2,2,0,81,8,1,
        0,0,0,82,83,5,64,0,0,83,84,5,101,0,0,84,85,5,110,0,0,85,86,5,100,
        0,0,86,87,5,61,0,0,87,88,5,118,0,0,88,89,5,102,0,0,89,90,5,112,0,
        0,90,91,5,64,0,0,91,93,1,0,0,0,92,94,5,13,0,0,93,92,1,0,0,0,93,94,
        1,0,0,0,94,95,1,0,0,0,95,96,5,10,0,0,96,97,1,0,0,0,97,98,6,3,3,0,
        98,10,1,0,0,0,99,101,9,0,0,0,100,99,1,0,0,0,101,104,1,0,0,0,102,
        103,1,0,0,0,102,100,1,0,0,0,103,106,1,0,0,0,104,102,1,0,0,0,105,
        107,5,13,0,0,106,105,1,0,0,0,106,107,1,0,0,0,107,108,1,0,0,0,108,
        109,5,10,0,0,109,12,1,0,0,0,110,111,5,64,0,0,111,112,5,101,0,0,112,
        113,5,110,0,0,113,114,5,100,0,0,114,115,5,61,0,0,115,116,5,112,0,
        0,116,117,5,121,0,0,117,118,5,116,0,0,118,119,5,104,0,0,119,120,
        5,111,0,0,120,121,5,110,0,0,121,122,5,64,0,0,122,124,1,0,0,0,123,
        125,5,13,0,0,124,123,1,0,0,0,124,125,1,0,0,0,125,126,1,0,0,0,126,
        127,5,10,0,0,127,128,1,0,0,0,128,129,6,5,3,0,129,14,1,0,0,0,130,
        132,9,0,0,0,131,130,1,0,0,0,132,135,1,0,0,0,133,134,1,0,0,0,133,
        131,1,0,0,0,134,137,1,0,0,0,135,133,1,0,0,0,136,138,5,13,0,0,137,
        136,1,0,0,0,137,138,1,0,0,0,138,139,1,0,0,0,139,140,5,10,0,0,140,
        16,1,0,0,0,15,0,1,2,35,38,41,63,72,76,93,102,106,124,133,137,4,5,
        1,0,5,2,0,6,0,0,4,0,0
    ]

class conversionLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    Fox = 1
    Py = 2

    FoxStart = 1
    PyStart = 2
    Line = 3
    FoxEnd = 4
    FoxLine = 5
    PyEnd = 6
    PyLine = 7

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE", "Fox", "Py" ]

    literalNames = [ "<INVALID>",
 ]

    symbolicNames = [ "<INVALID>",
            "FoxStart", "PyStart", "Line", "FoxEnd", "FoxLine", "PyEnd", 
            "PyLine" ]

    ruleNames = [ "FoxStart", "PyStart", "Line", "FoxEnd", "FoxLine", "PyEnd", 
                  "PyLine" ]

    grammarFileName = "conversionLexer.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.11.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


